### ✅ 上下文长度（Context Length）简明总结：

> **上下文长度（如 128K tokens）** 是指：
>
> 👉 **每次与大模型通信时，API 请求中「输入的内容 + 模型的输出」的总 token 数**的上限。
>
> 这个限制包括：
>
> * 当前输入内容（prompt）
> * 拼接进去的历史对话
> * 模型生成的回复

### 🔍 关键点：

* **单位是 token**，不是字符、不是字节。
* 每次对话请求都是**独立的**，所谓“上下文连续”，是因为**历史被拼接进 prompt**。
* 如果总 token 超过限制，多余部分会被截断或报错。
* 比如 128K token，大概对应 25 万英文单词 或 40 万个汉字左右（视语言密度而定）。