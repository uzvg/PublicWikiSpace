created: 20250625025854177
description: LLM本质上是自然语言模型，而非API解析器，它最擅长理解人类对话式指令。
modified: 20250625030919368
progress: Completed
rating: Plain
tags: PermanentNotes AI(人工智能) PromptEngineering(提示词工程)
title: 什么样的文本更容易被大语言模型识别？
type: text/vnd.tiddlywiki
visibility: Public

!! 引言：

我一直以为，像`JSON`、或者像`XML`这样的结构化文本更容易被LLM识别，没想到，并非如此。

<<twks-tip "模型的本质是文本生成器，不是API解析器。优先让它像人类一样工作，再逐步添加机器友好层，而非反之。">>

!! 自然语言更易被大模型识别：

对于“让模型更好理解，同时便于你生成和控制提示”的目标，推荐顺序如下：

# 自然语言嵌入结构（最佳）
# 自然语言 + markdown 表格 / bullet / header（次佳）
# JSON（可选，仅用于模型做结构化输出时）
# XML（不推荐，一般只有特定领域才使用）

; 优势如下：
* ''模型理解力最强''：LLM（大语言模型）本质上是自然语言模型，它最擅长理解人类对话式的指令。
* ''抗格式错误''：即使表述稍有不严谨（如漏掉逗号、用词偏差），模型也能通过语义理解意图。
* ''人工编辑友好''：非技术人员也能快速修改提示词。

; 潜在缺点：
* 复杂结构（如嵌套条件）可能表达不够精确（但可通过分步指令优化）。

; ➠ 最佳场景：
* 95%的日常需求。
* 尤其适合：对话系统、开放创作、多步骤任务指令。